{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain surface visualization\n",
    "\n",
    "This tutorial will show you how to visualize neuroimaging data on brain surfaces.\n",
    "\n",
    "@author: Makliya Mamat (makliyamamat@gmail\\.com)\n",
    "\n",
    "\n",
    "- Understanding brain surface data and annotation files\n",
    "- Working with parcellation schemes and region names\n",
    "- Mapping data to brain vertices\n",
    "- Creating single and multi-view brain visualizations\n",
    "- Customizing colors, views, and layouts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up and understanding the basics\n",
    "\n",
    "First, let's import the necessary libraries and understand what we're working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainspace.plotting import plot_surf\n",
    "from brainstat.datasets import fetch_template_surface\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "\n",
    "# Set up matplotlib for better plots\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding brain surfaces\n",
    "\n",
    "Brain surfaces are 3D meshes that represent the cortical surface. The most commonly used template is the fsaverage surface from FreeSurfer. Let's load it and understand its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left hemisphere surface:\n",
      "  Number of vertices: 163842\n",
      "  Number of faces: 327680\n",
      "  Coordinates shape: (163842, 3)\n",
      "\n",
      "Right hemisphere surface:\n",
      "  Number of vertices: 163842\n",
      "  Number of faces: 327680\n",
      "  Coordinates shape: (163842, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load the fsaverage brain surface template\n",
    "# This gives us two surfaces: left and right hemispheres\n",
    "pial_left, pial_right = fetch_template_surface(\"fsaverage\", join=False)\n",
    "\n",
    "print(\"Left hemisphere surface:\")\n",
    "print(f\"  Number of vertices: {pial_left.n_points}\")\n",
    "print(f\"  Number of faces: {pial_left.n_cells}\")\n",
    "print(f\"  Coordinates shape: {pial_left.Points.shape}\")\n",
    "\n",
    "print(\"\\nRight hemisphere surface:\")\n",
    "print(f\"  Number of vertices: {pial_right.n_points}\")\n",
    "print(f\"  Number of faces: {pial_right.n_cells}\")\n",
    "print(f\"  Coordinates shape: {pial_right.Points.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts:**\n",
    "- **Vertices**: Points in 3D space that define the surface\n",
    "- **Faces**: Triangular polygons connecting vertices to form the mesh\n",
    "- **Coordinates**: 3D positions (x, y, z) of each vertex\n",
    "\n",
    "Each vertex can have associated data (like activation values, connectivity measures, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding annotation files\n",
    "\n",
    "Annotation files (.annot) contain information about which brain regions each vertex belongs to. Let's explore this in detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left hemisphere annotation file:\n",
      "  Number of vertices with labels: 163842\n",
      "  Number of unique regions: 154\n",
      "  Label range: 0 to 153\n",
      "\n",
      "Right hemisphere annotation file:\n",
      "  Number of vertices with labels: 163842\n",
      "  Number of unique regions: 158\n",
      "  Label range: 0 to 157\n"
     ]
    }
   ],
   "source": [
    "# Load parcellation labels from annotation files\n",
    "# These files tell us which region each vertex belongs to\n",
    "labels_lh, _, names_lh = nib.freesurfer.read_annot('parcs/lh.500.aparc.annot')\n",
    "labels_rh, _, names_rh = nib.freesurfer.read_annot('parcs/rh.500.aparc.annot')\n",
    "\n",
    "print(\"Left hemisphere annotation file:\")\n",
    "print(f\"  Number of vertices with labels: {len(labels_lh)}\")\n",
    "print(f\"  Number of unique regions: {len(names_lh)}\")\n",
    "print(f\"  Label range: {labels_lh.min()} to {labels_lh.max()}\")\n",
    "\n",
    "print(\"\\nRight hemisphere annotation file:\")\n",
    "print(f\"  Number of vertices with labels: {len(labels_rh)}\")\n",
    "print(f\"  Number of unique regions: {len(names_rh)}\")\n",
    "print(f\"  Label range: {labels_rh.min()} to {labels_rh.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 left hemisphere region names:\n",
      "  0: b'unknown_part1'\n",
      "  1: b'bankssts_part1'\n",
      "  2: b'bankssts_part2'\n",
      "  3: b'caudalanteriorcingulate_part1'\n",
      "  4: b'caudalmiddlefrontal_part1'\n",
      "  5: b'caudalmiddlefrontal_part2'\n",
      "  6: b'caudalmiddlefrontal_part3'\n",
      "  7: b'caudalmiddlefrontal_part4'\n",
      "  8: b'corpuscallosum_part1'\n",
      "  9: b'cuneus_part1'\n",
      "\n",
      "First 10 right hemisphere region names:\n",
      "  0: b'unknown_part1'\n",
      "  1: b'bankssts_part1'\n",
      "  2: b'bankssts_part2'\n",
      "  3: b'caudalanteriorcingulate_part1'\n",
      "  4: b'caudalmiddlefrontal_part1'\n",
      "  5: b'caudalmiddlefrontal_part2'\n",
      "  6: b'caudalmiddlefrontal_part3'\n",
      "  7: b'caudalmiddlefrontal_part4'\n",
      "  8: b'corpuscallosum_part1'\n",
      "  9: b'cuneus_part1'\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the region names (they're stored as byte strings)\n",
    "print(\"First 10 left hemisphere region names:\")\n",
    "for i, name in enumerate(names_lh[:10]):\n",
    "    print(f\"  {i}: {name}\")\n",
    "\n",
    "print(\"\\nFirst 10 right hemisphere region names:\")\n",
    "for i, name in enumerate(names_rh[:10]):\n",
    "    print(f\"  {i}: {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the annotation file structure:**\n",
    "- `labels_lh/rh`: Array where each element is the region ID for that vertex\n",
    "- `names_lh/rh`: List of region names corresponding to each ID\n",
    "- The label value at each vertex position tells us which region that vertex belongs to\n",
    "\n",
    "Let's decode the region names and create a comprehensive list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of regions: 312\n",
      "Left hemisphere regions: 154\n",
      "Right hemisphere regions: 158\n",
      "\n",
      "Example region names:\n",
      "  0: lh_unknown_part1\n",
      "  50: lh_lingual_part5\n",
      "  100: lh_rostralmiddlefrontal_part1\n",
      "  150: lh_insula_part1\n",
      "  200: rh_lateralorbitofrontal_part3\n",
      "  250: rh_precentral_part9\n",
      "  300: rh_supramarginal_part3\n"
     ]
    }
   ],
   "source": [
    "# Decode byte strings and add hemisphere prefixes for clarity\n",
    "names_lh_decoded = ['lh_' + name.decode('utf-8') for name in names_lh]\n",
    "names_rh_decoded = ['rh_' + name.decode('utf-8') for name in names_rh]\n",
    "\n",
    "# Combine all region names\n",
    "all_roi_names = names_lh_decoded + names_rh_decoded\n",
    "\n",
    "print(f\"Total number of regions: {len(all_roi_names)}\")\n",
    "print(f\"Left hemisphere regions: {len(names_lh_decoded)}\")\n",
    "print(f\"Right hemisphere regions: {len(names_rh_decoded)}\")\n",
    "\n",
    "print(\"\\nExample region names:\")\n",
    "for i, name in enumerate(all_roi_names[::50]):  # Every 50th region\n",
    "    print(f\"  {i*50}: {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding region centroids\n",
    "\n",
    "A centroid is the geometric center of a region. Let's calculate and visualize centroids for some regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_region_centroid(vertices, labels, region_id):\n",
    "    \"\"\"Calculate the centroid (center point) of a specific region.\"\"\"\n",
    "    # Find all vertices that belong to this region\n",
    "    region_vertices = vertices[labels == region_id]\n",
    "    \n",
    "    if len(region_vertices) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Calculate the mean of all vertex coordinates\n",
    "    centroid = np.mean(region_vertices, axis=0)\n",
    "    return centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region centroids (first 5 regions):\n",
      "\n",
      "Region 0:\n",
      "  lh_unknown_part1: [-12.92104666 -14.84461824  -2.90817507]\n",
      "  rh_unknown_part1: [ 14.45473246 -14.48470301  -2.68204723]\n"
     ]
    }
   ],
   "source": [
    "# Calculate centroids for a few example regions\n",
    "print(\"Region centroids (first 5 regions):\")\n",
    "for region_id in range(1):\n",
    "    centroid_lh = calculate_region_centroid(pial_left.Points, labels_lh, region_id)\n",
    "    centroid_rh = calculate_region_centroid(pial_right.Points, labels_rh, region_id)\n",
    "    \n",
    "    region_name_lh = names_lh_decoded[region_id] if region_id < len(names_lh_decoded) else \"N/A\"\n",
    "    region_name_rh = names_rh_decoded[region_id] if region_id < len(names_rh_decoded) else \"N/A\"\n",
    "    \n",
    "    print(f\"\\nRegion {region_id}:\")\n",
    "    if centroid_lh is not None:\n",
    "        print(f\"  {region_name_lh}: {centroid_lh}\")\n",
    "    if centroid_rh is not None:\n",
    "        print(f\"  {region_name_rh}: {centroid_rh}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with test data\n",
    "\n",
    "Let's load some test data and understand how to map it to brain regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (308,)\n",
      "Value range: -1.690 to 1.680\n",
      "Mean value: 0.008\n",
      "Standard deviation: 0.975\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test = pd.read_csv('data/test.csv', header=None, names=['region_name', 'value'])\n",
    "test_values = df_test['value'].values\n",
    "\n",
    "print(f\"Test data shape: {test_values.shape}\")\n",
    "print(f\"Value range: {test_values.min():.3f} to {test_values.max():.3f}\")\n",
    "print(f\"Mean value: {test_values.mean():.3f}\")\n",
    "print(f\"Standard deviation: {test_values.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 test values:\n",
      "  0: 0.457\n",
      "  1: 0.072\n",
      "  2: 0.240\n",
      "  3: 1.420\n",
      "  4: 0.330\n",
      "  5: 1.110\n",
      "  6: 1.250\n",
      "  7: -1.510\n",
      "  8: -1.560\n",
      "  9: 0.251\n"
     ]
    }
   ],
   "source": [
    "# Show first few values\n",
    "print(\"\\nFirst 10 test values:\")\n",
    "for i, val in enumerate(test_values[:10]):\n",
    "    print(f\"  {i}: {val:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and preparing region data\n",
    "\n",
    "Some regions in parcellation schemes are not useful for analysis (like corpus callosum, unknown regions). Let's filter them out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions to be excluded: ['lh_unknown_part1', 'lh_corpuscallosum_part1', 'rh_unknown_part1', 'rh_corpuscallosum_part1']\n",
      "\n",
      "Total regions: 312\n",
      "Valid regions (after exclusion): 308\n",
      "Excluded regions: 4\n"
     ]
    }
   ],
   "source": [
    "# Define regions to exclude (these are typically not useful for cortical analysis)\n",
    "excluded_rois = {\n",
    "    'lh_unknown_part1', 'rh_unknown_part1', \n",
    "    'lh_corpuscallosum_part1', 'rh_corpuscallosum_part1'\n",
    "}\n",
    "\n",
    "# Find which regions are being excluded\n",
    "excluded_found = [name for name in all_roi_names if name in excluded_rois]\n",
    "print(f\"Regions to be excluded: {excluded_found}\")\n",
    "\n",
    "# Create list of valid (real) regions\n",
    "valid_roi_names = [name for name in all_roi_names if name not in excluded_rois]\n",
    "\n",
    "print(f\"\\nTotal regions: {len(all_roi_names)}\")\n",
    "print(f\"Valid regions (after exclusion): {len(valid_roi_names)}\")\n",
    "print(f\"Excluded regions: {len(all_roi_names) - len(valid_roi_names)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping data to brain vertices\n",
    "\n",
    "This is a crucial step: we need to map our region-level data to individual vertices on the brain surface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value dictionary size: 308\n",
      "Test values used: 308\n",
      "Regions with data: 308\n",
      "Regions with NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from region names to values\n",
    "# We'll map our test data to the valid regions\n",
    "value_dict = {}\n",
    "for i, region in enumerate(valid_roi_names):\n",
    "    if i < len(test_values):\n",
    "        value_dict[region] = test_values[i]\n",
    "    else:\n",
    "        value_dict[region] = np.nan  # Fill missing regions with NaN\n",
    "\n",
    "print(f\"Value dictionary size: {len(value_dict)}\")\n",
    "print(f\"Test values used: {len(test_values)}\")\n",
    "print(f\"Regions with data: {sum(1 for v in value_dict.values() if not np.isnan(v))}\")\n",
    "print(f\"Regions with NaN: {sum(1 for v in value_dict.values() if np.isnan(v))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left hemisphere vertex values:\n",
      "  Shape: (163842,)\n",
      "  Non-NaN values: 149953\n",
      "  Value range: -1.690 to 1.680\n",
      "\n",
      "Right hemisphere vertex values:\n",
      "  Shape: (163842,)\n",
      "  Non-NaN values: 148752\n",
      "  Value range: -1.690 to 1.680\n"
     ]
    }
   ],
   "source": [
    "def map_values_to_vertices(labels, roi_names, value_dict, excluded_rois):\n",
    "    \"\"\"Map region-level values to individual vertices.\n",
    "    \n",
    "    Args:\n",
    "        labels: Array of region IDs for each vertex\n",
    "        roi_names: List of region names corresponding to IDs\n",
    "        value_dict: Dictionary mapping region names to values\n",
    "        excluded_rois: Set of region names to exclude\n",
    "    \n",
    "    Returns:\n",
    "        Array of values for each vertex\n",
    "    \"\"\"\n",
    "    vertex_values = []\n",
    "    \n",
    "    for label in labels:\n",
    "        # Check if this is a valid region ID\n",
    "        if 0 <= label < len(roi_names):\n",
    "            region_name = roi_names[label]\n",
    "            \n",
    "            # Check if this region should be excluded\n",
    "            if region_name not in excluded_rois:\n",
    "                vertex_values.append(value_dict.get(region_name, np.nan))\n",
    "            else:\n",
    "                vertex_values.append(np.nan)\n",
    "        else:\n",
    "            vertex_values.append(np.nan)\n",
    "    \n",
    "    return np.array(vertex_values)\n",
    "\n",
    "# Map values to vertices for both hemispheres\n",
    "vertex_values_lh = map_values_to_vertices(labels_lh, all_roi_names, value_dict, excluded_rois)\n",
    "vertex_values_rh = map_values_to_vertices(labels_rh, all_roi_names, value_dict, excluded_rois)\n",
    "\n",
    "print(f\"Left hemisphere vertex values:\")\n",
    "print(f\"  Shape: {vertex_values_lh.shape}\")\n",
    "print(f\"  Non-NaN values: {np.sum(~np.isnan(vertex_values_lh))}\")\n",
    "print(f\"  Value range: {np.nanmin(vertex_values_lh):.3f} to {np.nanmax(vertex_values_lh):.3f}\")\n",
    "\n",
    "print(f\"\\nRight hemisphere vertex values:\")\n",
    "print(f\"  Shape: {vertex_values_rh.shape}\")\n",
    "print(f\"  Non-NaN values: {np.sum(~np.isnan(vertex_values_rh))}\")\n",
    "print(f\"  Value range: {np.nanmin(vertex_values_rh):.3f} to {np.nanmax(vertex_values_rh):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data to brain surfaces\n",
    "\n",
    "Now we'll attach our vertex-level data to the brain surface objects so they can be visualized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully added to brain surfaces.\n",
      "Left surface data shape: (163842,)\n",
      "Right surface data shape: (163842,)\n"
     ]
    }
   ],
   "source": [
    "# Add our data to the brain surfaces\n",
    "# The 'p' parameter means we're adding point data (vertex-level data)\n",
    "pial_left.append_array(vertex_values_lh, name='test_data', at='p')\n",
    "pial_right.append_array(vertex_values_rh, name='test_data', at='p')\n",
    "\n",
    "print(\"Data successfully added to brain surfaces.\")\n",
    "print(f\"Left surface data shape: {pial_left.PointData['test_data'].shape}\")\n",
    "print(f\"Right surface data shape: {pial_right.PointData['test_data'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic single-view sisualization\n",
    "\n",
    "Let's start with simple single-view visualizations to understand the basics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/apple/Tutorials/visualizing_neuroimaging/figures/single_view_lateral.png'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple single-view plot (left hemisphere, lateral view)\n",
    "plot_surf(\n",
    "    {'lh': pial_left},  # Surface as dictionary with key\n",
    "    [['lh']],  # Layout specification for single view\n",
    "    array_name=[['test_data']],  # Data array to visualize\n",
    "    cmap='viridis',  # Color map\n",
    "    nan_color=(0.7, 0.7, 0.7, 1),  # Color for NaN values (gray)\n",
    "    color_bar=True,  # Show color bar\n",
    "    zoom=1.2,  # Zoom level\n",
    "    interactive=False,  # Don't open interactive window\n",
    "    screenshot=True,  # Save as image\n",
    "    transparent_bg=False,\n",
    "    filename='figures/single_view_lateral.png',\n",
    "    size=(1000, 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/apple/Tutorials/visualizing_neuroimaging/figures/single_view_medial.png'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a different view - medial (inside) view\n",
    "plot_surf(\n",
    "    {'lh': pial_left},  # Surface as dictionary with key\n",
    "    [['lh']],  # Layout specification for single view\n",
    "    array_name=[['test_data']],  # Data array to visualize\n",
    "    view=[['medial']],  # Medial view shows the inside of the hemisphere\n",
    "    cmap='viridis',\n",
    "    nan_color=(0.7, 0.7, 0.7, 1),\n",
    "    color_bar=True,\n",
    "    zoom=1.2,\n",
    "    interactive=False,\n",
    "    screenshot=True,\n",
    "    transparent_bg=False,\n",
    "    filename='figures/single_view_medial.png',\n",
    "    size=(1000, 1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different color schemes\n",
    "\n",
    "Let's explore different color maps to see how they affect the visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color map 'viridis' saved to figures/color_map_viridis.png\n",
      "Color map 'plasma' saved to figures/color_map_plasma.png\n",
      "Color map 'inferno' saved to figures/color_map_inferno.png\n",
      "Color map 'coolwarm' saved to figures/color_map_coolwarm.png\n",
      "Color map 'RdYlBu_r' saved to figures/color_map_RdYlBu_r.png\n"
     ]
    }
   ],
   "source": [
    "# Try different color maps\n",
    "color_maps = ['viridis', 'plasma', 'inferno', 'coolwarm', 'RdYlBu_r']\n",
    "\n",
    "for cmap in color_maps:\n",
    "    plot_surf(\n",
    "        {'lh': pial_left},  # Surface as dictionary with key\n",
    "        [['lh']],  # Layout specification for single view\n",
    "        array_name=[['test_data']],  # Data array to visualize\n",
    "        view=[['lateral']],  # View specification\n",
    "        cmap=cmap,\n",
    "        nan_color=(0.7, 0.7, 0.7, 1),\n",
    "        color_bar=True,\n",
    "        zoom=1.2,\n",
    "        interactive=False,\n",
    "        screenshot=True,\n",
    "        transparent_bg=False,\n",
    "        filename=f'figures/color_map_{cmap}.png',\n",
    "        size=(1000, 1000)\n",
    "    )\n",
    "    print(f\"Color map '{cmap}' saved to figures/color_map_{cmap}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-view visualization\n",
    "\n",
    "Now let's create side-by-side views to compare different perspectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/apple/Tutorials/visualizing_neuroimaging/figures/two_view_lh.png'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a two-view plot (lateral and medial of left hemisphere)\n",
    "plot_surf(\n",
    "    {'lh': pial_left},  # Surface as dictionary with key\n",
    "    [['lh', 'lh']],  # Two views side by side (both using 'lh' key)\n",
    "    array_name=[['test_data']],  # Data array for both views\n",
    "    view=[['lateral', 'medial']],  # View specifications for each panel\n",
    "    cmap='viridis',\n",
    "    nan_color=(0.7, 0.7, 0.7, 1),\n",
    "    color_bar=True,\n",
    "    zoom=1.2,\n",
    "    interactive=False,\n",
    "    screenshot=True,\n",
    "    transparent_bg=False,\n",
    "    filename='figures/two_view_lh.png',\n",
    "    size=(1400, 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-view plot (both hemispheres) saved to figures/two_view_hemispheres.png\n"
     ]
    }
   ],
   "source": [
    "# Create a two-view plot comparing left and right hemispheres\n",
    "plot_surf(\n",
    "    {'lh': pial_left, 'rh': pial_right},  # Both hemispheres\n",
    "    [['lh', 'rh']],  # Left and right side by side\n",
    "    array_name=[['test_data']],  # Same data for both\n",
    "    view=[['lateral', 'lateral']],  # Both in lateral view\n",
    "    cmap='viridis',\n",
    "    nan_color=(0.7, 0.7, 0.7, 1),\n",
    "    color_bar=True,\n",
    "    zoom=1.2,\n",
    "    interactive=False,\n",
    "    screenshot=True,\n",
    "    transparent_bg=False,\n",
    "    filename='figures/two_view_hemispheres.png',\n",
    "    size=(1400, 1000)\n",
    ")\n",
    "\n",
    "print(\"Two-view plot (both hemispheres) saved to figures/two_view_hemispheres.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four-view visualization\n",
    "\n",
    "The most comprehensive view shows all four perspectives: left lateral, left medial, right lateral, and right medial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/apple/Tutorials/visualizing_neuroimaging/figures/four_view_comprehensive.png'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the comprehensive four-view plot\n",
    "plot_surf(\n",
    "    {'lh': pial_left, 'rh': pial_right},  # Both hemispheres\n",
    "    [['lh', 'lh', 'rh', 'rh']],  # Left, left, right, right\n",
    "    array_name=[['test_data']],  # Data array\n",
    "    view=[['lateral', 'medial', 'lateral', 'medial']],  # Views for each panel\n",
    "    cmap='viridis',\n",
    "    nan_color=(0.7, 0.7, 0.7, 1),\n",
    "    color_bar=True,\n",
    "    zoom=1.2,\n",
    "    interactive=False,\n",
    "    screenshot=True,\n",
    "    transparent_bg=False,\n",
    "    filename='figures/four_view_comprehensive.png',\n",
    "    size=(1400, 1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom color bar\n",
    "\n",
    "Sometimes you want more control over the color bar. Let's create a custom one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot without the built-in color bar\n",
    "plot_surf(\n",
    "    {'lh': pial_left, 'rh': pial_right},\n",
    "    [['lh', 'lh', 'rh', 'rh']],\n",
    "    array_name=[['test_data']],\n",
    "    view=[['lateral', 'medial', 'lateral', 'medial']],\n",
    "    cmap='viridis',\n",
    "    nan_color=(0.7, 0.7, 0.7, 1),\n",
    "    color_bar=False,  # Disable built-in color bar\n",
    "    zoom=1.2,\n",
    "    interactive=False,\n",
    "    screenshot=True,\n",
    "    transparent_bg=False,\n",
    "    filename='figures/brain_without_colorbar.png',\n",
    "    size=(1400, 1000))\n",
    "\n",
    "# Create a custom color bar\n",
    "valid_values = test_values[~np.isnan(test_values)]\n",
    "vmin = np.min(valid_values)\n",
    "vmax = np.max(valid_values)\n",
    "\n",
    "fig, cbar_ax = plt.subplots(figsize=(0.8, 3.0), dpi=300)\n",
    "norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "sm = plt.cm.ScalarMappable(cmap='viridis', norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "cbar = plt.colorbar(sm, ax=cbar_ax, orientation='vertical', shrink=1.0, aspect=10)\n",
    "cbar.set_ticks([vmin, vmax])\n",
    "cbar.set_ticklabels([f'{vmin:.2f}', f'{vmax:.2f}'])\n",
    "cbar.ax.tick_params(labelsize=9)\n",
    "cbar_ax.remove()\n",
    "\n",
    "# Save the custom color bar\n",
    "plt.savefig('figures/custom_colorbar.png', bbox_inches='tight', dpi=300, facecolor='white')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the brain image with the custom color bar\n",
    "brain_img = Image.open('figures/brain_without_colorbar.png')\n",
    "cbar_img = Image.open('figures/custom_colorbar.png')\n",
    "\n",
    "# Create final composite image\n",
    "final_width = brain_img.size[0] + cbar_img.size[0] + 20\n",
    "final_height = brain_img.size[1]\n",
    "final_image = Image.new('RGB', (final_width, final_height), (255, 255, 255))\n",
    "\n",
    "# Paste brain image\n",
    "final_image.paste(brain_img, (0, 0))\n",
    "\n",
    "# Paste color bar on the right\n",
    "cbar_x = brain_img.size[0] + 20\n",
    "cbar_y = (final_height - cbar_img.size[1]) // 2\n",
    "final_image.paste(cbar_img, (cbar_x, cbar_y))\n",
    "\n",
    "# Save the final composite\n",
    "final_image.save('figures/final_composite.png', dpi=(300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Next:\n",
    "- Try different parcellation schemes\n",
    "- Experiment with different data types\n",
    "- Explore interactive visualization tools\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
